#!/usr/bin/env python3
"""
Optimize the DSPy workflow using training data from test cases.

This script creates a comprehensive optimization pipeline for the DSPy agents.
"""

import os
import sys
import json
from typing import List, Dict
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add src directory to path
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'src'))

def create_optimization_dataset():
    """Create training examples from successful test runs."""
    print("üîÑ Creating optimization dataset...")
    
    # Load previous test results if available
    results_file = "dspy_test_results.json"
    if os.path.exists(results_file):
        with open(results_file, 'r') as f:
            results = json.load(f)
        
        successful_tasks = [r for r in results if r.get('status') == 'success']
        print(f"  Found {len(successful_tasks)} successful examples")
        
        return successful_tasks
    else:
        print("  No previous results found. Run tests first with: python run_dspy_tests.py --all")
        return []

def optimize_signatures():
    """Optimize DSPy signatures based on performance data."""
    print("üéØ Optimizing DSPy signatures...")
    
    # Implementation would analyze which signatures perform best
    # and suggest improvements
    
    optimization_tips = [
        "Use specific, detailed field descriptions",
        "Include example formats in output fields", 
        "Add constraints for better guidance",
        "Use task-specific signatures for different problem types"
    ]
    
    for tip in optimization_tips:
        print(f"  üí° {tip}")

def analyze_failure_patterns():
    """Analyze common failure patterns to improve prompts."""
    print("üìä Analyzing failure patterns...")
    
    # Check for common error patterns in logs
    common_issues = [
        "Type conversion errors (Bool ‚Üî Prop)",
        "Missing parentheses in proofs", 
        "Incorrect tactic sequences",
        "Incomplete pattern matching"
    ]
    
    for issue in common_issues:
        print(f"  ‚ö†Ô∏è  Common issue: {issue}")

def optimize_rag_retrieval():
    """Optimize RAG retrieval for better examples."""
    print("üîç Optimizing RAG retrieval...")
    
    try:
        from src.embedding_db import EmbeddingDB
        
        # Test RAG performance with different queries
        db = EmbeddingDB()
        db.load_from_pickle("lean4_embeddings_chunks.pkl", "lean4_embeddings.npy")
        
        # Test queries for different problem types
        test_queries = [
            "natural number addition proof",
            "boolean logic operations", 
            "array operations existence",
            "modular arithmetic divisibility",
            "conditional if-then-else proof"
        ]
        
        for query in test_queries:
            results = db.get_similar_examples(query, k=3)
            print(f"  üìã Query '{query}': {len(results)} results")
            
    except Exception as e:
        print(f"  ‚ùå RAG optimization failed: {e}")

def suggest_model_configurations():
    """Suggest optimal model configurations."""
    print("‚öôÔ∏è  Model Configuration Suggestions...")
    
    suggestions = {
        "Planning": "gpt-4o (better at problem analysis)",
        "Code Generation": "gpt-4o (better at structured output)",
        "Proof Generation": "o3-mini (better at mathematical reasoning)",
        "Verification": "gpt-4o (faster feedback loops)"
    }
    
    for task, model in suggestions.items():
        print(f"  üîß {task}: {model}")

def create_performance_report():
    """Create a comprehensive performance report."""
    print("üìà Creating performance report...")
    
    report = {
        "optimization_date": "2025-01-31",
        "total_tasks": 11,
        "documentation_chunks": 57,
        "embedding_dimensions": 384,
        "suggested_improvements": [
            "Use problem-specific signatures",
            "Implement progressive complexity",
            "Add more Lean 4 examples",
            "Fine-tune retrieval parameters"
        ]
    }
    
    with open("optimization_report.json", 'w') as f:
        json.dump(report, f, indent=2)
    
    print("  üìÑ Report saved to optimization_report.json")

def main():
    print("üöÄ DSPy Workflow Optimization")
    print("=" * 50)
    
    # Run optimization steps
    dataset = create_optimization_dataset()
    optimize_signatures()
    analyze_failure_patterns()
    optimize_rag_retrieval()
    suggest_model_configurations()
    create_performance_report()
    
    print("\n" + "=" * 50)
    print("‚ú® Optimization complete!")
    print("\nNext steps:")
    print("  1. Review optimization_report.json")
    print("  2. Run tests to measure improvements")
    print("  3. Iterate on signature designs")
    print("  4. Fine-tune prompt strategies")

if __name__ == "__main__":
    main()